{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from boruta import BorutaPy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell reads in parameters and response data from Excel files and combines them into a single dataframe\n",
    "# Check cell outputs to make sure everything looks good\n",
    "\n",
    "# parameters_file = \"Multi-Threshold Analysis Data\" # Excel file to pull parameters from\n",
    "# parameters_sheet = \"Suzuki Yields and Parameters\" # Sheet in the Excel file to pull parameters from\n",
    "# parameters_start_col = 2   # 0-indexed column number where the parameters start\n",
    "# parameters_num_parameters = 190 # Number of parameters in the parameters file\n",
    "# parameters_num_responses = 450 # Number of responses/ligands in the parameters file\n",
    "# parameters_y_label_col = 0  # 0-indexed column number where the ligand labels are\n",
    "# parameters_header_rows = 0 # Number of rows to skip when reading the parameters\n",
    "\n",
    "# response_file = \"Multi-Threshold Analysis Data\" # Excel file to pull responses from\n",
    "# response_sheet = \"Suzuki Yields and Parameters\" # Sheet in the Excel file to pull responses from\n",
    "# response_num_samples = 450 # Number of samples/reactions in the response file\n",
    "# response_col = 1 # 0-indexed column number for the responses\n",
    "# response_y_label_col = 0  # 0-indexed column number where the ligand labels are\n",
    "# response_header_rows = 1 # Number of rows to skip when reading the responses\n",
    "\n",
    "# RESPONSE_LABEL = \"Yield (%)\" # How you want to refer to your response variable in the dataframe\n",
    "\n",
    "parameters_file = \"8_16_combined_basic_parameters\" # Excel file to pull parameters from\n",
    "parameters_sheet = \"Sheet1\" # Sheet in the Excel file to pull parameters from\n",
    "parameters_start_col = 2   # 0-indexed column number where the parameters start\n",
    "parameters_num_parameters = 3247 # Number of parameters in the parameters file\n",
    "parameters_num_responses = 192 # Number of responses/ligands in the parameters file\n",
    "parameters_y_label_col = 0  # 0-indexed column number where the ligand labels are\n",
    "parameters_header_rows = 0 # Number of rows to skip when reading the parameters\n",
    "\n",
    "response_file = \"8_16_combined_basic_parameters\" # Excel file to pull responses from\n",
    "response_sheet = \"Sheet1\" # Sheet in the Excel file to pull responses from\n",
    "response_num_samples = 450 # Number of samples/reactions in the response file\n",
    "response_col = 1 # 0-indexed column number for the responses\n",
    "response_y_label_col = 0  # 0-indexed column number where the ligand labels are\n",
    "response_header_rows = 0 # Number of rows to skip when reading the responses\n",
    "\n",
    "RESPONSE_LABEL = \"Pdt/Hydro\" # How you want to refer to your response variable in the dataframe\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------------\n",
    "# EDIT ABOVE THIS LINE\n",
    "# --------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Actually start reading stuff into dataframes\n",
    "parameters_df = pd.read_excel(\"./InputData/\" + parameters_file + \".xlsx\",\n",
    "                              parameters_sheet,\n",
    "                              header = parameters_header_rows,\n",
    "                              index_col = parameters_y_label_col,\n",
    "                              nrows = parameters_num_responses + 1,\n",
    "                              usecols = list(range(0, (parameters_num_parameters + parameters_start_col)))\n",
    "                              )\n",
    "response_df = pd.read_excel(\"./InputData/\" + response_file + \".xlsx\",\n",
    "                            response_sheet,\n",
    "                            header = response_header_rows,\n",
    "                            index_col = response_y_label_col,\n",
    "                            nrows = response_num_samples,\n",
    "                            usecols = list(range(0, response_col + 1))\n",
    "                            )\n",
    "\n",
    "\n",
    "# Drop any columns before parameters_start_col that are not the index column\n",
    "parameters_columns_to_keep = [col for col in range(0, len(parameters_df.columns)) if col >= parameters_start_col-1]\n",
    "parameters_df = parameters_df.iloc[:,parameters_columns_to_keep]\n",
    "\n",
    "# Combine the two dataframes into the master dataframe\n",
    "response_df.drop(response_df.columns[0:response_col-1], axis = 'columns', inplace = True)\n",
    "data_df = response_df.merge(parameters_df, left_index = True, right_index = True)\n",
    "data_df.rename(columns = {data_df.columns.values[0]: RESPONSE_LABEL}, inplace = True) # Converts the output column name from whatever it is on the spreadsheet\n",
    "data_df.dropna(inplace = True) # Remove any rows with blanks\n",
    "\n",
    "# This converts all the data to numeric values since it was reading them in as non-numeric objects for some reason\n",
    "for column in data_df.columns:\n",
    "    data_df[column] = pd.to_numeric(data_df[column], errors='coerce')\n",
    "\n",
    "# Print out the data distribution of the response variable\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.hist(data_df[RESPONSE_LABEL], color='grey')\n",
    "plt.xlabel(RESPONSE_LABEL, fontsize=14)\n",
    "plt.ylabel(\"Frequency\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# Display the dataframe\n",
    "display(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a cell below to run depending on which cross terms you want, then save/export them with the final cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Cross-Terms Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell appends all possible cross terms to the main dataframe\n",
    "\n",
    "new_columns = {}\n",
    "parameter_columns = data_df.drop(columns=[RESPONSE_LABEL]).columns\n",
    "\n",
    "for parameter1 in parameter_columns:\n",
    "    for parameter2 in parameter_columns:\n",
    "        if parameter1 != parameter2:\n",
    "            crossterm = parameter1 + \" * \" + parameter2\n",
    "            new_columns[crossterm] = data_df[parameter1] * data_df[parameter2]\n",
    "\n",
    "print(f'Number of cross terms: {len(new_columns)}')\n",
    "\n",
    "cross_terms_df = pd.DataFrame(new_columns)\n",
    "cross_terms_df = pd.concat([data_df, cross_terms_df], axis=1)\n",
    "\n",
    "display(cross_terms_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitted Cros-Terms Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell appends all cross terms made from a subset of parameters to the main dataframe\n",
    "\n",
    "parameters_to_cross = range(1, 50)\n",
    "# parameters_to_cross = list(range(0, 10)) + list(range(20, 30)) # Example of how to cross a non-continuous subset of parameters\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "parameter_columns = data_df.columns[parameters_to_cross]\n",
    "print(f'Selected parameters: {list(parameter_columns)}')\n",
    "\n",
    "new_columns = {}\n",
    "\n",
    "for parameter1 in parameter_columns:\n",
    "    for parameter2 in parameter_columns:\n",
    "        if parameter1 != parameter2:\n",
    "            crossterm = parameter1 + \" * \" + parameter2\n",
    "            new_columns[crossterm] = data_df[parameter1] * data_df[parameter2]\n",
    "\n",
    "print(f'Number of cross terms: {len(new_columns)}')\n",
    "\n",
    "cross_terms_df = pd.DataFrame(new_columns)\n",
    "cross_terms_df = pd.concat([data_df, cross_terms_df], axis=1)\n",
    "\n",
    "display(cross_terms_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Terms Between Ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell appends all cross terms made by crossing two subsets of parameters to the main dataframe\n",
    "\n",
    "parameters_to_cross_1 = range(1, 10)\n",
    "parameters_to_cross_2 = range(21, 30)\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "parameter_columns_1 = data_df.columns[parameters_to_cross_1]\n",
    "parameter_columns_2 = data_df.columns[parameters_to_cross_2]\n",
    "print(f'First selected parameter set: {list(parameter_columns_1)}')\n",
    "print(f'Second selected parameter set: {list(parameter_columns_2)}')\n",
    "\n",
    "new_columns = {}\n",
    "\n",
    "for parameter1 in parameter_columns_1:\n",
    "    for parameter2 in parameter_columns_2:\n",
    "        if parameter1 != parameter2:\n",
    "            crossterm = parameter1 + \" * \" + parameter2\n",
    "            new_columns[crossterm] = data_df[parameter1] * data_df[parameter2]\n",
    "\n",
    "print(f'Number of cross terms: {len(new_columns)}')\n",
    "\n",
    "cross_terms_df = pd.DataFrame(new_columns)\n",
    "cross_terms_df = pd.concat([data_df, cross_terms_df], axis=1)\n",
    "\n",
    "display(cross_terms_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Cross-Terms Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will export the dataframe to an Excel file in the InputData folder\n",
    "# It will add a blank row between the column names and the data due to how it handles the MultiIndex, so you may want to delete that row before using the data\n",
    "\n",
    "export_filename = 'cross_terms.xlsx'\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "cross_terms_df.to_excel(f'OutputData/{export_filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boruta Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit the Boruta feature selector\n",
    "# Basically all of the arguments here are default so you might play around with them to suit your needs\n",
    "# Once you get up into the 1000s of features, it might take a while to run, especially if you're using the full cross-term dataset\n",
    "# In the final itteration, the number of rejected features is reported incorrectly but everything is still running properly (according to the BorutaPy documentation)\n",
    "\n",
    "# Only use one of the following lines\n",
    "boruta_df = data_df.copy() # If you want to use the original data\n",
    "# boruta_df = cross_terms_df.copy() # If you want to use the data with cross terms\n",
    "\n",
    "# Set details of the random forest regressor to be used in the Boruta feature selector\n",
    "rf = RandomForestRegressor(n_jobs=-1, max_depth=5)\n",
    "\n",
    "# {perc} is the percentage of the maximum importance of the shadow features to set as the cutoff\n",
    "    # Lower {perc} means you'll get more false positive features kept, but are less likely to discard relevant features\n",
    "# {max_iter} is the maximum number of iterations to run before stopping\n",
    "    # Let it go longer if you want to more fully resolve the tentative features\n",
    "feat_selector = BorutaPy(rf, n_estimators='auto', verbose=2, random_state=1, perc=75, max_iter=100) \n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------------\n",
    "# EDIT ABOVE THIS LINE\n",
    "# --------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Run the Boruta feature selector\n",
    "parameter_columns = boruta_df.drop(columns=[RESPONSE_LABEL]).columns\n",
    "feat_selector.fit(np.asarray(boruta_df[parameter_columns]), np.asarray(boruta_df[RESPONSE_LABEL]))\n",
    "\n",
    "# Compile the names of confirmed and tentatively accepted features into a list\n",
    "parameters_confirmed = [parameter_columns[i] for i in range(0,len(feat_selector.support_)) if feat_selector.support_[i]]\n",
    "parameters_tentative = [parameter_columns[i] for i in range(0,len(feat_selector.support_)) if feat_selector.support_weak_[i]]\n",
    "parameters_confirmed.extend(parameters_tentative)\n",
    "\n",
    "# Build the final dataframe with the output and only the confirmed and tentatively accepted features\n",
    "columns_to_keep = [RESPONSE_LABEL] + [column for column in boruta_df.columns if column in parameters_confirmed]\n",
    "boruta_df_output = boruta_df[columns_to_keep]\n",
    "display(boruta_df_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Boruta Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will export the dataframe to an Excel file in the InputData folder\n",
    "# It will add a blank row between the column names and the data due to how it handles the MultiIndex, so you may want to delete that row before using the data\n",
    "\n",
    "export_filename = 'boruta_parameters.xlsx'\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------------\n",
    "display(boruta_df_output)\n",
    "\n",
    "boruta_df_output.to_excel(f'OutputData/{export_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
